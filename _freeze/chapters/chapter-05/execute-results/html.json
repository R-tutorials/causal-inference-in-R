{
  "hash": "a41640633f3bcbe01a71c7a006b0f2a7",
  "result": {
    "markdown": "# Expressing causal questions as DAGs {#sec-dags}\n\n\n\n\n\n## Visualizing Causal Assumptions\n\n> Draw your assumptions before your conclusions --@hernan2021\n\nCausal diagrams are a tool to visualize your assumptions about the causal structure of the questions you're trying to answer.\nIn a randomized experiment, the causal structure is quite simple: while there may be many causes of an outcome, the only cause of the exposure is the randomization process itself (we hope!).\nIn many non-randomized settings, however, the structure of your question can be a complex web of causality.\nCausal diagrams help communicate what we think this structure looks like.\nIn addition to being open about what we think the causal structure is, causal diagrams have incredible mathematics properties that allow us to identify a way to estimate unbiased causal effects even with observational data.\n\nCausal diagrams are also increasingly common.\nData collected as a review of the use of causal diagrams in applied health research papers show a drastic increase in use over time [@Tennant2021].\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Percentage of health research papers using causal diagrams over time.](chapter-05_files/figure-html/fig-dag-usage-1.png){#fig-dag-usage width=672}\n:::\n:::\n\n\nThe type of causal diagrams we use are also called directed acyclic graphs (DAGs).\nThese graphs are directed because they include arrows going in a specific direction.\nThey're acyclic because they don't go in circles; a variable can't cause itself, for instance.\nDAGs are used for a wide variety of problems, but we're specificaly concerned with *causal* DAGs.\nThis class of DAGs is also sometimes referred to as Structural Causal Models (SCMs) because they are a model of the causal structure of a question.\n\n::: callout-tip\n## DAGs down under\n\nWe highly recommend asking an Australian friend about DAGs.\n:::\n\nDAGs depict causal relationships between variables.\nVisually, the way they depict variables is as *edges* and *nodes*.\nEdges are the arrows going from one variable to another, also sometimes called arcs or just arrows.\nNodes are the variables themselves, sometimes called vertices, points, or just variables.\nin @fig-dag-basic, there are two nodes: `x` and `y` and one edge going from `x` to `y`.\nHere, we are saying that `x` causes `y`.\nIn some capacity, `y` \"listens\" to `x`.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-dag-basic-1.png){#fig-dag-basic width=288}\n:::\n:::\n\n\nIf we're interested in the causal effect of `x` on `y`, we're trying to estimate a numeric representation of that arrow.\nUsually, though, there are many other variables and arrows in the causal structure of a given question.\nA series of arrows is called a *path*.\nThere are three types of paths you'll see in DAGs: forks, chains, and colliders (sometimes called inverse forks).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-dag-path-types-1.png){#fig-dag-path-types width=672}\n:::\n:::\n\n\nForks represent a common cause of two variables.\nHere, we're saying that `q` causes both `x` and `y`.\nThis is the traditional definition of a confounder.\nThey're called forks because the arrows from `x` to `y` are in different directions.\nChains, on the other hand, represent a series of arrows going in the same direction.\nHere `q` is called a *mediator*: it is along the causal path from `x` to `y`.\nIn this diagram, the only path from `x` to `y` is the one mediated through `q`.\nFinally, a collider is a path where two arrowheads meet at a variable.\nBecause causality always goes forward in time, this naturally means that the collider variable is caused by two other variables.\nHere, we're saying that `x` and `y` both cause `q`.\n\n::: callout-tip\n## Are DAGs SEMs?\n\nIf you're familiar with structural equation models (SEMs), a modeling technique commonly used in psychology and other social science settings, you may notice some similarities between SEMs and DAGs.\nIn fact, DAGs are a form of *non-parametric* SEM.\nSEMs estimate entire graphs using parametric assumptions.\nCausal DAGs, on the other hand, don't estimate anything; an arrow going from one variable to another says nothing about the strength or functional form of that relationship, only that we think it exists.\n:::\n\nOne of the major benefits of DAGs is that they help us identify sources of bias and, often, provide clues in how to address them.\nHowever, talking about an unbiased effect estimate only makes sense when we have a specific causal question in mind.\nSince each arrow represents a cause, it's causality all the way down, so no individual arrow is inherently problematic.\nHere, we're interested in the effect of `x` on `y`.\nThis question defines which paths we're interested in and which we're not.\n\nThese three types of paths have different implications for the statistical relationship between `x` and `y`.\nIf we only look at the correlation between the two variables under these assumptions:\n\n1.  In the fork, `x` and `y` will be associated, despite there being no arrow from `x` to `y`.\n2.  In the chain, `x` and `y` are related but only through `q`.\n3.  In the collider, `x` and `y` will *not* be related.\n\nPaths that transmit association are called *open paths*.\nPaths that do not transmit association are called *closed paths*.\nForks and chains are open while colliders are closed.\n\nSo, should we adjust for `q`?\nThat depends on the nature of the path.\nForks are confounding paths.\nBecause `q` causes both `x` and `y`, `x` and `y` will have a spurious association.\nThey both contain information from `q`, their mutual cause, and that mutual causal relationship makes `x` and `y` associated statistically.\nAdjusting for `q` will *block* the bias from confounding and give us the true relationship between `x` and `y`.\n\n::: callout-tip\n## Adjustment\n\nWe can use a variety of techniques to account for a variable.\nWe use the term \"adjustment\" to generally refer to any technique that removes the effect of variables we're not interested in.\n:::\n\n@fig-confounder-scatter depicts this effect visually.\nHere, `x` and `y` are continuous, and by definition of the DAG, they are unrelated.\n`q`, however, causes both.\nThe unadjusted effect is biased because it includes information about the open path from `x` to `y` via `z`.\nWithin levels of `z`, however, `x` and `y` are unrelated.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-confounder-scatter-1.png){#fig-confounder-scatter width=672}\n:::\n:::\n\n\nFor chains, whether or not we adjusting for mediators depends on the research question.\nHere, adjusting for `q` would result in a null estimate of the effect of `x` on `y`.\nBecause the only effect of `x` on `y` is via `q`, no other effect remains.\nThe effect of `x` on `y` mediated by `q` is called the *indirect* effect, while the effect of `x` on `y` directly is called the *direct* effect.\nIf we're only interested in the direct effect, controlling for `q` might be what we want.\nIf we want to know about both effects, we shouldn't try to adjust for `q`.\nWe'll learn more estimating different mediation effects in @sec-mediation.\n\n@fig-mediator-scatter shows this effect visually.\nThe unadjusted effect of `x` on `y` represents the total effect.\nSince the total effect is due entirely to the path mediated by `q`, when we adjust for `q`, no relationship remains.\nThis is the direct effect.\nNeither of these effects is due to bias but rather each answers a different research question.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-mediator-scatter-1.png){#fig-mediator-scatter width=672}\n:::\n:::\n\n\nColliders are different.\nIn the collider DAG of @fig-dag-path-types, `x` and `y` are *not* associated, but both cause `q`.\nAdjusting for `q` has the opposite effect than with confounding: it *opens* a biasing pathway.\nSometimes, people draw the path opened up by conditioning on a collider connecting `x` and `y`.\n\nVisually, we can see this happen when `x` and `y` are continuous and `q` is binary.\nIn @fig-collider-scatter, when we don't include `q`, we find there is no relationship between `x` and `y`.\nThat's the correct result.\nHowever, when we include `q`, we can detect information about both `x` and `y`, and they appear correlated: across levels of `x`, those with `q = 0` have lower levels of `y`.\nAssociation seemingly flows back in time.\nOf course, that can't happen from a causal perspective, so controlling for `q` is the wrong thing to do.\nWe end up with a biased effect of `x` on `y`.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-collider-scatter-1.png){#fig-collider-scatter width=672}\n:::\n:::\n\n\nHow can this be?\nSince `x` and `y` happen before `q`, `q` can't have an impact on them.\nLet's turn the DAG on its side and consider @fig-collider-time.\nIf we break down the two time points, at time point 1, `q` hasn't happened yet, and `x` and `y` are unrelated.\nAt time point 2, `q` happens due to `x` and `y`.\nBut causality only goes forward in time.\n`q` happening later can't change the fact that `x` and `y` happened independently at time point 1.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-collider-time-1.png){#fig-collider-time width=672}\n:::\n:::\n\n\nCausality only goes forward.\nAssociation, however, is time-agnostic.\nIt's just an observation about the numerical relationships between variables.\nWhen we control for the future, we run the risk of introducing bias.\nIt's challenging to develop an intuition for this.\nConsider a case where `x` and `y` are the only causes of `q`, and all three variables are binary.\nWhen *either* `x` or `y` equals 1, then `q` happens.\nIf we know `q = 1` and `x = 0` then logically it must be that `y = 1`.\nThus, knowing about `q` gives us information about `y` via `x`.\nThis is an extreme example, but it shows how this type of bias, sometimes called *collider-stratification bias* or *selection bias*, occurs: conditioning on `q` provides statistical information about `x` and `y` and distorts their relationship.\n\n::: callout-tip\n## Exchangability revisited\n\nWe commonly refer exchangability as the assumption of no confounding.\nActually, this isn't quite right.\nIt's the assumption of no *open, non-causal* paths.\nMany times, these are confounding pathways.\nHowever, paths can also be opened by conditioning on a collider.\nEven though these aren't confounders, it creates non-exchangability between the two groups: they are different in a way that matters to the exposure and outcome.\n\nOpen, non-causal paths are also called *backdoor paths*.\nWe'll use this terminology often because it captures the idea well: these are any open paths that are biasing the effect we're interested in estimating\n:::\n\nCorrectly identifying the causal structure between the exposure and outcome thus helps us 1) communicate the assumptions we're making about the relationships between variables and 2) identify sources of bias.\nImportantly, in doing 2), we are also often able to identify ways to prevent bias based on the assumptions in 1).\nIn the simple case of three DAGs in @fig-dag-path-types, we know whether or not to control for `q` depending on the nature of the causal structure.\nThe set or sets of variables we need to adjust for is called the *adjustment set*.\nDAGs can help us identify adjustment sets even in complex settings.\n\n::: callout-tip\n## What about interaction?\n\nDAGs don't make a statement about interaction or effect estimate modification even though they are an important part of inference.\nTechnically, interaction is a matter of the functional form of the relationships in the DAG.\nMuch as we don't need to specify how we're going to model a variable in the DAG (e.g., with splines), we don't need to specify how variables statistically interact with one another.\nThat's a matter for the modeling stage.\n\nThere are several ways we use interactions in causal inference.\nIn one extreme, they are simply a matter of functional form: interaction terms are included in models but marginalized over to get an overall causal effect.\nIn the other extreme, we're interested in *joint causal effects*, where the two variables interacting with each other are both causal.\nIn between, we can use interaction terms to identify *heterogenous causal effects*, effects which vary by a second variable that is not assumed to be causal.\nAs with many tools in causal inference, we use the same statistical technique many ways to answer different questions.\n\n<!-- TODO: expand on this later in the book and link to chapter where we'll discuss -->\n\nMany people have tried ways of expressing interaction in DAGs using different types of arcs, nodes, and other annotations, but no approach has taken off as the preferred way.\n:::\n\nLet's take a look at an example in R.\nWe'll learn how to build DAGs, visualize them, and identify important information like adjustment sets.\n\n## DAGs in R\n\nFirst, let's consider the a research question: Does listening to a comedy podcast the morning before an exam improve graduate students test scores?\nWe can diagram this using the method describe in @sec-diag (@fig-diagram-podcast).\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Does listening to a comedy podcast the morning before an exam improve graduate student test scores?](../images/podcast-diagram.png){#fig-diagram-podcast width=2267}\n:::\n:::\n\n\nThe main tool we'll use for making DAGs is ggdag.\nggdag is a package that connects ggplot2, the most powerful visualization tool in R, to dagitty, an R package with sophisticated algorithms for querying DAGs.\n\nTo create a DAG object, we'll use the `dagify()` function.`dagify()` returns a `dagitty` object that works with both the dagitty and ggdag packages.\nThe `dagify()` function takes formulas, separated by commas, that specify causes and effects, with the left element of of the formula specifying the effect and the right all of the factors that cause it.\nThis is just like the type of formula we specify for most regression models in R.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndagify(\n  effect1 ~ cause1 + cause2 + cause3,\n  effect2 ~ cause1 + cause4,\n  ...\n)\n```\n:::\n\n\nWhat are all of the factors that cause graduate students to listen to a podcast the morning before an exam?\nWhat are all of the factors that could cause a graduate student to do well on a test?\nLet's posit some here.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(ggdag)\ndagify(\n  podcast ~ mood + humor + prepared,\n  exam ~ mood + prepared\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\ndag {\nexam\nhumor\nmood\npodcast\nprepared\nhumor -> podcast\nmood -> exam\nmood -> podcast\nprepared -> exam\nprepared -> podcast\n}\n```\n\n\n:::\n:::\n\n\nIn the code above, we assume that:\n\n-   a graduate student's mood, sense of humor, and how prepared they feel for the exam could influence whether they listened to a podcast the morning of the test\n-   their mood and how prepared they are also influences their exam score\n\nNotice we *do not* see podcast in the exam equation; this means that we assume that there is **no** causal relationship between podcast and the exam score.\n\nThere are some other useful arguments you'll often find yourself supplying to `dagify()`:\n\n-   `exposure` and `outcome`: Telling ggdag the variables that are the exposure and outcome of your research question is required for many of the most useful queries we can make of DAGs.\n-   `latent`: This argument lets us tell ggdag that some variables in the DAG are unmeasured. This is really useful for identifying valid adjustment sets with the data we actually have.\n-   `coords`: Coordinates for the variables. You can choose between algorithmic or manual layouts, as discussed in below. We'll use `time_ordered_coords()` here.\n-   `labels`: A character vector of labels for the variables.\n\nLet's create a DAG object, `podcast_dag`, that has some of these attributes, then visualize the DAG with `ggdag()`.\n`ggdag()` returns a ggplot object, so we can add additional layers to the plot like themes.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npodcast_dag <- dagify(\n  podcast ~ mood + humor + prepared,\n  exam ~ mood + prepared,\n  coords = time_ordered_coords(\n    list(\n      # time point 1\n      c(\"prepared\", \"humor\", \"mood\"), \n      # time point 2\n      \"podcast\",  \n      # time point 3\n      \"exam\"\n    )\n  ),\n  exposure = \"podcast\",\n  outcome = \"exam\",\n  labels = c(\n    podcast = \"podcast\",\n    exam = \"exam score\",\n    mood = \"mood\",\n    humor = \"humor\",\n    prepared = \"prepared\"\n  )\n)\nggdag(podcast_dag, use_labels = \"label\", text = FALSE) +\n  theme_dag()\n```\n\n::: {.cell-output-display}\n![Proposed DAG to answer the question: Does listening to a comedy podcast the morning before an exam improve graduate students test scores?](chapter-05_files/figure-html/fig-dag-podcast-1.png){#fig-dag-podcast width=384}\n:::\n:::\n\n\n::: callout-note\nFor the rest of the chapter, we'll use `theme_dag()`, a ggplot theme from ggdag meant for DAGs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntheme_set(\n  theme_dag() %+replace%\n    theme(\n      legend.position = \"bottom\",\n      strip.text.x = element_text(margin = margin(2, 0, 2, 0, \"mm\"))\n    )\n)\n```\n:::\n\n:::\n\n::: callout-tip\n## DAG coordinates\n\nYou don't need to specify coordinates to ggdag.\nIf you don't, it uses algorithms designed for automatic layouts.\nThere are many such algorithms, and they focus on different aspects of the layout, e.g. the shape, the space between the nodes, minimizing how many edges cross, etc.\nThese layout algorithms usually have a component of randomness, so it's good to use a seed if you want to get the same result.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\n# no coordinates specified\nset.seed(123)\npod_dag <- dagify(\n  podcast ~ mood + humor + prepared,\n  exam ~ mood + prepared\n)\n\n# automatically determine layouts\npod_dag |> \n  ggdag(text_size = 2.8)\n```\n\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/unnamed-chunk-14-1.png){fig-align='center' width=384}\n:::\n:::\n\n\nWe can also ask for a specific layout, e.g. the popular Sugiyama algorithm for DAGs\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npod_dag |> \n  ggdag(layout = \"sugiyama\", text_size = 2.8)\n```\n\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/unnamed-chunk-15-1.png){fig-align='center' width=384}\n:::\n:::\n\n\nFor causal DAGs, the time-ordered layout algorithm is often best, which we can specify with `time_ordered_coords()` or `layout = \"time_ordered\"`.\nWe'll discuss time ordering in greater detail in @sec-time-ordered.\nEarlier, we explicitly told ggdag which variables were at which time points, but we don't need to.\nNotice, though, that the time ordering algorithm puts `podcast` and `exam` at the same timepoint since one doesn't cause another (and thus predate it).\nWe know that's not the case: listening to the podcast happened before taking the exam.\n\n<!-- TODO: if implementing a better way to use this algorithm while specifying on or more time points then update this -->\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npod_dag |> \n  ggdag(layout = \"time_ordered\", text_size = 2.8)\n```\n\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/unnamed-chunk-16-1.png){fig-align='center' width=384}\n:::\n:::\n\n\nYou can also manually specify coordinates using a list or data frame and provide them to the `coords` argument of `dagify()`.\nAdditionally, because ggdag is based on dagitty, you can use `dagitty.net` to create and organize a DAG using a graphical interface, then export the result as dagitty code for ggdag to consume.\n\nAlgorithmic layouts are often nice for fast visualization of DAGs or particularly complex graphs.\nOnce you want to share your DAG, it's usually best to be a little more intentional about the layout, perhaps by specifying the coordinates manually.\n`time_ordered_coords()` is often the best of both worlds, and we'll use it for most DAGs in this book.\n:::\n\nWe've specified the DAG for this question and told ggdag what the exposure and outcome of interest are.\nAccording to the DAG, there is no direct causal relationship between listening to a podcast and exam scores.\nAre there any other open paths?\n`ggdag_paths()` takes a DAG and visualizes the open paths.\nIn @fig-paths-podcast, we see two open paths: `podcast <- mood -> exam\"` and `podcast <- prepared -> exam`. These are both forks---*confounding pathways*. Since there is no causal relationship between listening to a podcast and exam scores, the only open paths are *backdoor* paths, these two confounding pathways.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# TODO: Why aren't okabe-ito colors propgating here and other spots in ggdag?\npodcast_dag |> \n  # show the whole dag as a light gray \"shadow\" \n  # rather than just the paths\n  ggdag_paths(shadow = TRUE, text = FALSE, use_labels = \"label\")\n```\n\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-paths-podcast-1.png){#fig-paths-podcast width=672}\n:::\n:::\n\n\n::: callout-tip\n`dagify()` returns a `dagitty()` object, but underneath the hood, ggdag converts `dagitty` objects to tidy DAGs, a structure that holds both the `dagitty` object and a `dataframe` about the DAG.\nThis is handy if you want to manipulate the DAG programatically.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npodcast_dag_tidy <- podcast_dag |> \n  tidy_dagitty()\n\npodcast_dag_tidy\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A DAG with 5 nodes and 5 edges\n#\n# Exposure: podcast\n# Outcome: exam\n#\n# A tibble: 7 × 9\n  name         x     y direction to       xend  yend\n  <chr>    <int> <int> <fct>     <chr>   <int> <int>\n1 exam         3     0 <NA>      <NA>       NA    NA\n2 humor        1     0 ->        podcast     2     0\n3 mood         1     1 ->        exam        3     0\n4 mood         1     1 ->        podcast     2     0\n5 podcast      2     0 <NA>      <NA>       NA    NA\n6 prepared     1    -1 ->        exam        3     0\n7 prepared     1    -1 ->        podcast     2     0\n# ℹ 2 more variables: circular <lgl>, label <chr>\n```\n\n\n:::\n:::\n\n\nMost of the quick plotting functions transform the `dagitty` object to a tidy DAG if it's not already, then manipulate the data in some capacity.\nFor instance, `dag_paths()` underlies `ggdag_paths()`; it returns a tidy DAG with data about the paths.\nYou can use several dplyr functions on these objects directly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npodcast_dag_tidy |> \n  dag_paths() |> \n  filter(set == 2, path == \"open path\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A DAG with 3 nodes and 2 edges\n#\n# Exposure: podcast\n# Outcome: exam\n#\n# A tibble: 4 × 11\n  set   name        x     y direction to     xend  yend\n  <chr> <chr>   <int> <int> <fct>     <chr> <int> <int>\n1 2     exam        3     0 <NA>      <NA>     NA    NA\n2 2     podcast     2     0 <NA>      <NA>     NA    NA\n3 2     prepar…     1    -1 ->        exam      3     0\n4 2     prepar…     1    -1 ->        podc…     2     0\n# ℹ 3 more variables: circular <lgl>, label <chr>,\n#   path <chr>\n```\n\n\n:::\n:::\n\n\nTidy DAGs are not pure data frames, but you can retrieve either the `dataframe` or `dagitty` object to work with them directly using `pull_dag_data()` or `pull_dag()`.\n`pull_dag()` can be useful when you want to work with dagitty functions:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(dagitty)\npodcast_dag_tidy |> \n  pull_dag() |> \n  paths()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n$paths\n[1] \"podcast <- mood -> exam\"    \n[2] \"podcast <- prepared -> exam\"\n\n$open\n[1] TRUE TRUE\n```\n\n\n:::\n:::\n\n:::\n\nBackdoor paths pollute the statistical association between `podcast` and `exam`, so we need to account for them.\n`ggdag_adjustment_set()` visualizes any valid adjustment sets implied by the DAG.\n@fig-podcast-adustment-set shows variables that are adjusted for as squares.\nAny arrows that were coming out of adjusted variables are removed from the DAG, because the path is longer open at that variable.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggdag_adjustment_set(\n  podcast_dag, \n  text = FALSE, \n  use_labels = \"label\"\n)\n```\n\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-podcast-adustment-set-1.png){#fig-podcast-adustment-set fig-align='center' width=384}\n:::\n:::\n\n\n@fig-podcast-adustment-set shows the *minimal adjustment set*.\nBy default, ggdag returns the set(s) that can close all backdoor paths with the fewest number of variables possible.\nIn this DAG, that's just one set: `mood` and `prepared`.\nThis makes sense, because there are two backdoor paths and the only other variables on them besides the exposure and outcome are these two variables.\nSo, at minimum, we need to account for both to get a valid estimate.\n\n::: {.callout-tip}\n`ggdag()` and friends usually use `tidy_dagitty()` and `dag_*()` or `node_*()` functions to change the underlying data frame.\nSimilarly, the quick plotting functions use ggdag's geoms to visualize the resulting DAG(s).\nIn other words, you can use the same data manipulation and visualization strategies that you use day-to-day directly with ggdag.\n\nHere's a condensed version of what `ggdag_adjustment_set()` is doing:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\npodcast_dag_tidy |> \n  # add adjustment sets to data\n  dag_adjustment_sets() |>\n  ggplot(aes(\n    x = x, y = y, xend = xend, yend = yend,\n    color = adjusted, shape = adjusted\n  )) + \n  # ggdag's custom geoms: add nodes, edges, and labels\n  geom_dag_point() + \n  # remove adjusted paths\n  geom_dag_edges_link(data = \\(.df) filter(.df, adjusted != \"adjusted\")) + \n  geom_dag_label_repel() + \n  # you can use any ggplot function, too\n  facet_wrap(~ set) +\n  scale_shape_manual(values = c(adjusted = 15, unadjusted = 19))\n```\n\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/unnamed-chunk-22-1.png){fig-align='center' width=432}\n:::\n:::\n\n:::\n\nMinimal adjustment sets are only one type of valid adjustment sets.\nSometimes, there are other combinations of variables that can get us an unbiased effect estimate.\nTwo other options available in ggdag are full adjustment sets and canonical adjustment sets.\nFull adjustment sets are are every combination of variables that result in a valid set.\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nggdag_adjustment_set(\n  podcast_dag, \n  text = FALSE, \n  use_labels = \"label\",\n  # get full adjustment sets\n  type = \"all\"\n)\n```\n\n::: {.cell-output-display}\n![](chapter-05_files/figure-html/fig-adustment-set-all-1.png){#fig-adustment-set-all fig-align='center' width=624}\n:::\n:::\n\n\nIt turns out that we can also control for `humor` without biasing the result.\n\nCanonical adjusment sets are a bit more complex: they are all possible ancestors of the exposure and outcome minus any possible descendants.\nIn fully saturated DAGs (DAGs where every node causes anything that comes after it in time), the canonical adjustment set is the minimal adjustment set.\n\n::: callout-tip\nMost of the functions in ggdag use dagitty underneath the hood.\nIt's often useful to call dagitty functions directly.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadjustmentSets(podcast_dag, type = \"canonical\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n{ humor, mood, prepared }\n```\n\n\n:::\n:::\n\n:::\n\nUsing our proposed DAG, let's simulate some data to see how accounting for the minimal adjustment set might occur in practice.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(10)\nsim_data <- podcast_dag |>\n  simulate_data()\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsim_data\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 500 × 5\n     exam  humor   mood podcast prepared\n    <dbl>  <dbl>  <dbl>   <dbl>    <dbl>\n 1 -0.435  0.263 -0.100  -0.630   1.07  \n 2 -0.593  0.317  0.143  -1.55    0.0640\n 3  0.786  1.97  -0.591  -0.318  -0.439 \n 4 -0.103  2.86  -0.139   1.07    0.754 \n 5 -0.614 -2.39   0.702   0.464   0.356 \n 6  1.01   1.21   0.910   0.769   0.561 \n 7  0.167 -1.37  -0.559  -0.866   0.214 \n 8  1.16   0.164 -0.743   0.969  -1.67  \n 9  0.650  0.215 -0.248   0.691  -0.303 \n10  0.156  0.713  1.19   -1.02   -0.219 \n# ℹ 490 more rows\n```\n\n\n:::\n:::\n\n\nSince we have simulated this data, we know that this is a case where *standard methods will succeed* (see @sec-standard) and therefore can estimate the causal effect using a basic linear regression model.\n@fig-dag-sim shows a forest plot of the simulated data based on our DAG.\nNotice the model that only included the exposure resulted in a spurious effect (an estimate of -0.1 when we know the truth is 0), whereas the model that adjusted for the two variables as suggested by `ggdag_adjustment_set()` is not spurious (0.0).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n## Model that does not close backdoor paths\nunadjusted_model <- lm(exam ~ podcast, sim_data) |>\n  broom::tidy(conf.int = TRUE) |>\n  dplyr::filter(term == \"podcast\") |>\n  mutate(formula = \"podcast\")\n\n## Model that closes backdoor paths\nadjusted_model <- lm(exam ~ podcast + mood + prepared, sim_data) |>\n  broom::tidy(conf.int = TRUE) |>\n  dplyr::filter(term == \"podcast\") |>\n  mutate(formula = \"podcast + mood + prepared\")\n\nbind_rows(\n  unadjusted_model,\n  adjusted_model\n) |>\n  ggplot(aes(x = estimate, y = formula, xmin = conf.low, xmax = conf.high)) +\n  geom_vline(xintercept = 0, linewidth = 1, color = \"grey80\") +\n  geom_pointrange(fatten = 3, size = 1) +\n  theme_minimal(18) +\n  labs(\n    y = NULL,\n    caption = \"correct effect size: 0\"\n  )\n```\n\n::: {.cell-output-display}\n![Forest plot of simulated data based on the DAG described in @fig-dag-podcast](chapter-05_files/figure-html/fig-dag-sim-1.png){#fig-dag-sim width=672}\n:::\n:::\n\n\n## Structures of Causality\n\n-   advanced forms of confounding, e.g. L happens after X\n-   Selection bias, M-Bias, Butterfly bias. L2FU later.\n-   instrumental variables, precision/competing exposure variables\n\n## Recommendations in building DAGs\n\nIn principle, using DAGs is easy: you specify the causal relationships you think exist and then query the DAG for information like valid adjustment sets. In practice, assembling DAGs takes considerable time and thought. In fact, next to defining the research question itself, it's one of the hardest steps in making causal inference. Very little guidance exists on best practices in assembling DAGs. @Tennant2021 collected data on DAGs in applied health research to better understand how they were being used. @tbl-dag-properties shows some information they collected: the median number of nodes and arcs in a DAG, their ration, the saturation percent of the DAG, and how many were fully saturated. Saturating DAGs means adding all possible arrows going forward in time, e.g. in a fully saturated DAG, any given variable at time point 1 has arrows going to all variables in future time points, and so on. Most DAGs were only about half saturated and very few were fully saturated. \n\nOnly about half of the papers using DAGs reported the adjustment set used. In other words, researchers presented their assumptions about the research question but not the implications about how they should handle the modeling stage or if in fact they did use a valid adjustment set. Similarly, the majority of studies did not report the estimand of interest.\n\n::: {.callout-note} \nThe estimand is the target of interest in terms of what it is we're trying to estimate, as discussed briefly in [Chapter -@sec-whole-game]. We'll discuss estimands in detail in [Chapter -@sec-estimands].\n:::\n\n\n::: {#tbl-dag-properties .cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"kwsxntypwf\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#kwsxntypwf table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#kwsxntypwf thead, #kwsxntypwf tbody, #kwsxntypwf tfoot, #kwsxntypwf tr, #kwsxntypwf td, #kwsxntypwf th {\n  border-style: none;\n}\n\n#kwsxntypwf p {\n  margin: 0;\n  padding: 0;\n}\n\n#kwsxntypwf .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#kwsxntypwf .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#kwsxntypwf .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#kwsxntypwf .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#kwsxntypwf .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#kwsxntypwf .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#kwsxntypwf .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#kwsxntypwf .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#kwsxntypwf .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#kwsxntypwf .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#kwsxntypwf .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#kwsxntypwf .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#kwsxntypwf .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#kwsxntypwf .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#kwsxntypwf .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kwsxntypwf .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#kwsxntypwf .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#kwsxntypwf .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#kwsxntypwf .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kwsxntypwf .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#kwsxntypwf .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kwsxntypwf .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#kwsxntypwf .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kwsxntypwf .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#kwsxntypwf .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#kwsxntypwf .gt_left {\n  text-align: left;\n}\n\n#kwsxntypwf .gt_center {\n  text-align: center;\n}\n\n#kwsxntypwf .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#kwsxntypwf .gt_font_normal {\n  font-weight: normal;\n}\n\n#kwsxntypwf .gt_font_bold {\n  font-weight: bold;\n}\n\n#kwsxntypwf .gt_font_italic {\n  font-style: italic;\n}\n\n#kwsxntypwf .gt_super {\n  font-size: 65%;\n}\n\n#kwsxntypwf .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#kwsxntypwf .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#kwsxntypwf .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#kwsxntypwf .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#kwsxntypwf .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#kwsxntypwf .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#kwsxntypwf .gt_indent_5 {\n  text-indent: 25px;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_left\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;Characteristic&lt;/strong&gt;\"><strong>Characteristic</strong></th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"&lt;strong&gt;N = 144&lt;/strong&gt;&lt;span class=&quot;gt_footnote_marks&quot; style=&quot;white-space:nowrap;font-style:italic;font-weight:normal;&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/span&gt;\"><strong>N = 144</strong><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span></th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"2\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"&lt;strong&gt;DAG properties&lt;/strong&gt;\"><strong>DAG properties</strong></th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"dag_prop  label\" class=\"gt_row gt_left\">Number of Nodes</td>\n<td headers=\"dag_prop  stat_0\" class=\"gt_row gt_center\">12 (9, 16)</td></tr>\n    <tr><td headers=\"dag_prop  label\" class=\"gt_row gt_left\">Number of Arcs</td>\n<td headers=\"dag_prop  stat_0\" class=\"gt_row gt_center\">29 (19, 41)</td></tr>\n    <tr><td headers=\"dag_prop  label\" class=\"gt_row gt_left\">Node to Arc Ratio</td>\n<td headers=\"dag_prop  stat_0\" class=\"gt_row gt_center\">2.30 (1.78, 3.00)</td></tr>\n    <tr><td headers=\"dag_prop  label\" class=\"gt_row gt_left\">Saturation Proportion</td>\n<td headers=\"dag_prop  stat_0\" class=\"gt_row gt_center\">0.46 (0.31, 0.67)</td></tr>\n    <tr><td headers=\"dag_prop  label\" class=\"gt_row gt_left\">Fully Saturated</td>\n<td headers=\"dag_prop  stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"dag_prop  label\" class=\"gt_row gt_left\">    Yes</td>\n<td headers=\"dag_prop  stat_0\" class=\"gt_row gt_center\">4 (3%)</td></tr>\n    <tr><td headers=\"dag_prop  label\" class=\"gt_row gt_left\">    No</td>\n<td headers=\"dag_prop  stat_0\" class=\"gt_row gt_center\">140 (97%)</td></tr>\n    <tr class=\"gt_group_heading_row\">\n      <th colspan=\"2\" class=\"gt_group_heading\" scope=\"colgroup\" id=\"&lt;strong&gt;Reporting&lt;/strong&gt;\"><strong>Reporting</strong></th>\n    </tr>\n    <tr class=\"gt_row_group_first\"><td headers=\"reporting  label\" class=\"gt_row gt_left\">Reported Estimand</td>\n<td headers=\"reporting  stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"reporting  label\" class=\"gt_row gt_left\">    Yes</td>\n<td headers=\"reporting  stat_0\" class=\"gt_row gt_center\">40 (28%)</td></tr>\n    <tr><td headers=\"reporting  label\" class=\"gt_row gt_left\">    No</td>\n<td headers=\"reporting  stat_0\" class=\"gt_row gt_center\">104 (72%)</td></tr>\n    <tr><td headers=\"reporting  label\" class=\"gt_row gt_left\">Reported Adjustment Set</td>\n<td headers=\"reporting  stat_0\" class=\"gt_row gt_center\"><br /></td></tr>\n    <tr><td headers=\"reporting  label\" class=\"gt_row gt_left\">    Yes</td>\n<td headers=\"reporting  stat_0\" class=\"gt_row gt_center\">80 (56%)</td></tr>\n    <tr><td headers=\"reporting  label\" class=\"gt_row gt_left\">    No</td>\n<td headers=\"reporting  stat_0\" class=\"gt_row gt_center\">64 (44%)</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"2\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;\"><sup>1</sup></span> Median (IQR); n (%)</td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n\n:::\n:::\n\nIn this section, we'll offer some advice from @Tennant2021 and our own experience assembling DAGs.\n\n### Iterate early and often\n\n-   Ideally before when designing your research, at least before analyzing data (avoid overfitting)\n\n### Consider your question\n\n-   estimand\n-   population and context\n\n### Order nodes by time {#chapter-05-sec-time-ordered}\n\n-   Time ordering algorithm\n-   Feedback loops: global warming and A/C use\n\n### Consider the whole data collection process\n\n-   race/shooting (show the `effect` argument of `adjustmentSets` to get direct effect)\n-   healthy worker bias\n\n### Include variables you don't have\n\n-   Examples where you can and can't adjust depending\n\n### Saturate your DAG then prune\n\n### Include instruments and competing exposures\n\n### Focus on the causal structure, then consider measurement bias\n\n### Be accurate, but focus on clarity\n\n### Pick adjustment sets most likely to be succesful\n\n-   measurement error, certainty\n-   use the path with the most observed variables\n\n### Use robustness checks\n\n-   Negative controls/Falsification end-points, dag-data consitency, alternate adjustment sets\n\n## Causal Inference is not (just) a statistical problem {#chapter-05-sec-quartets}\n\n-   This may be better off as the next chapter\n\n### Causal and Predictive Models, Revisited {#chapter-05-sec-causal-pred-revisit}\n\n-   Probably too long, but if possible, condense to a popout\n-   DAGs showing examples where prediction can lean on measured confounders, colliders. It's the amount of information a variable brings, not whether the coeffecient is unbiased affect of variable on outcome.\n-   Not practical to fit a prediction model with future variable\n-   Table 2 Bias examples. Unmeasure confounding of Z-Y relationship. Mediation example.\n",
    "supporting": [
      "chapter-05_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}